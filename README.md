This project focuses on implementing a face presentation attack detection system using the MTCNN (Multi-Task Cascaded Convolutional Neural Network), YOLOv5 (You Only Look Once), and Hugging Face's library. The MTCNN is utilized for face detection, alignment, and extraction, enabling accurate localization of faces within images or video frames. YOLOv5 serves as the backbone for detecting presentation attacks, such as printed photos or masks, by identifying anomalous facial features or artifacts. Hugging Face's library provides pre-trained models and tools for fine-tuning and evaluating deep learning models, streamlining the development process. By integrating these components, the project aims to create a robust and efficient system capable of detecting face presentation attacks in real-time or batch processing scenarios, with potential applications in security, authentication, and surveillance. The repository includes code, documentation, and pretrained models necessary for training, testing, and deploying the face presentation attack detection system.
